{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Missing Value Ratio\n",
    "\n",
    "2. Low Variance Filter\n",
    "\n",
    "3. High Correlation Filter\n",
    "\n",
    "4. Random Forest\n",
    "\n",
    "5. Backward Feature Elimination\n",
    "\n",
    "6. Forward Feature Selection\n",
    "\n",
    "7. Factor Analysis\n",
    "\n",
    "8. Principal Component Analysis\n",
    "\n",
    "9. Independent Component Analysis\n",
    "\n",
    "10. Methods Based on Projections\n",
    "\n",
    "11. t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "12. UMAP\n",
    "\n",
    "Applications of Various Dimensionality Reduction Techniques\n",
    "\n",
    "### From here: https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "train=pd.read_csv(\"train_kOBLwZA.csv\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Missing Value Ratio\n",
    "\n",
    "Suppose you’re given a dataset. What would be your first step? You would naturally want to explore the data first before building model. While exploring the data, you find that your dataset has some missing values. Now what? You will try to find out the reason for these missing values and then impute them or drop the variables entirely which have missing values (using appropriate methods).\n",
    "\n",
    "What if we have too many missing values (say more than 50%)? Should we impute the missing values or drop the variable? I would prefer to drop the variable since it will not have much information. However, this isn’t set in stone. We can set a threshold value and if the percentage of missing values in any variable is more than that threshold, we will drop the variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Identifier               0.000000\n",
      "Item_Weight                  17.165317\n",
      "Item_Fat_Content              0.000000\n",
      "Item_Visibility               0.000000\n",
      "Item_Type                     0.000000\n",
      "Item_MRP                      0.000000\n",
      "Outlet_Identifier             0.000000\n",
      "Outlet_Establishment_Year     0.000000\n",
      "Outlet_Size                  28.276428\n",
      "Outlet_Location_Type          0.000000\n",
      "Outlet_Type                   0.000000\n",
      "Item_Outlet_Sales             0.000000\n",
      "dtype: float64\n",
      "['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Location_Type', 'Outlet_Type', 'Item_Outlet_Sales']\n"
     ]
    }
   ],
   "source": [
    "# checking the percentage of missing values in each variable\n",
    "print(train.isnull().sum()/len(train)*100)\n",
    "\n",
    "# saving missing values in a variable\n",
    "a = train.isnull().sum()/len(train)*100\n",
    "# saving column names in a variable\n",
    "variables = train.columns\n",
    "variable = [ ]\n",
    "for i in range(0,12):\n",
    "    if a[i]<=20:   #setting the threshold as 20%\n",
    "        variable.append(variables[i])\n",
    "        \n",
    "# variable is the list that has miss data less the threshold (20% in this example)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Low Variance Filter\n",
    "\n",
    "Consider a variable in our dataset where all the observations have the same value, say 1. If we use this variable, do you think it can improve the model we will build? The answer is no, because this variable will have zero variance.\n",
    "\n",
    "So, we need to calculate the variance of each variable we are given. Then drop the variables having low variance as compared to other variables in our dataset. The reason for doing this, as I mentioned above, is that variables with a low variance will not affect the target variable.\n",
    "\n",
    "Let’s first impute the missing values in the Item_Weight column using the median value of the known Item_Weight observations. For the Outlet_Size column, we will use the mode of the known Outlet_Size values to impute the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Identifier              0.0\n",
      "Item_Weight                  0.0\n",
      "Item_Fat_Content             0.0\n",
      "Item_Visibility              0.0\n",
      "Item_Type                    0.0\n",
      "Item_MRP                     0.0\n",
      "Outlet_Identifier            0.0\n",
      "Outlet_Establishment_Year    0.0\n",
      "Outlet_Size                  0.0\n",
      "Outlet_Location_Type         0.0\n",
      "Outlet_Type                  0.0\n",
      "Item_Outlet_Sales            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train['Item_Weight'].fillna(train['Item_Weight'].median(), inplace=True)\n",
    "train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)\n",
    "# check the missing value again\n",
    "print(train.isnull().sum()/len(train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Weight                  1.786956e+01\n",
      "Item_Visibility              2.662335e-03\n",
      "Item_MRP                     3.878184e+03\n",
      "Outlet_Establishment_Year    7.008637e+01\n",
      "Item_Outlet_Sales            2.912141e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show variance\n",
    "print(train.var())\n",
    "\n",
    "# implenment the variance filter\n",
    "numeric = train[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]\n",
    "var = numeric.var()\n",
    "numeric = numeric.columns\n",
    "variable = [ ]\n",
    "for i in range(0,len(var)):\n",
    "    if var[i]>=10:   #setting the threshold as 10%\n",
    "       variable.append(numeric[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Correlation filter\n",
    "\n",
    "High correlation between two variables means they have similar trends and are likely to carry similar information. This can bring down the performance of some models drastically (linear and logistic regression models, for instance). We can calculate the correlation between independent numerical variables that are numerical in nature. If the correlation coefficient crosses a certain threshold value, we can drop one of the variables (dropping a variable is highly subjective and should always be done keeping the domain in mind).\n",
    "\n",
    "As a general guideline, we should keep those variables which show a decent or high correlation with the target variable.\n",
    "\n",
    "Let’s perform the correlation calculation in Python. We will drop the dependent variable (Item_Outlet_Sales) first and save the remaining variables in a new dataframe (df).\n",
    "\n",
    "We don’t have any variables with a high correlation in our dataset. Generally, if the correlation between a pair of variables is greater than 0.5-0.6, we should seriously consider dropping one of those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014168</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>0.007739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>-0.014168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.074834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0.024951</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <td>0.007739</td>\n",
       "      <td>-0.074834</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Item_Weight  Item_Visibility  Item_MRP  \\\n",
       "Item_Weight                   1.000000        -0.014168  0.024951   \n",
       "Item_Visibility              -0.014168         1.000000 -0.001315   \n",
       "Item_MRP                      0.024951        -0.001315  1.000000   \n",
       "Outlet_Establishment_Year     0.007739        -0.074834  0.005020   \n",
       "\n",
       "                           Outlet_Establishment_Year  \n",
       "Item_Weight                                 0.007739  \n",
       "Item_Visibility                            -0.074834  \n",
       "Item_MRP                                    0.005020  \n",
       "Outlet_Establishment_Year                   1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=train.drop('Item_Outlet_Sales', 1)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest\n",
    "\n",
    "Random Forest is one of the most widely used algorithms for feature selection. It comes packaged with in-built feature importance so you don’t need to program that separately. This helps us select a smaller subset of features.\n",
    "\n",
    "We need to convert the data into numeric form by applying one hot encoding, as Random Forest (Scikit-Learn Implementation) takes only numeric inputs. Let’s also drop the ID variables (Item_Identifier and Outlet_Identifier) as these are just unique numbers and hold no significant importance for us currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df=df.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)\n",
    "df=pd.get_dummies(df)\n",
    "\n",
    "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "model.fit(df,train.Item_Outlet_Sales)\n",
    "\n",
    "features = df.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above graph, we can hand pick the top-most features to reduce the dimensionality in our dataset. Alernatively, we can use the SelectFromModel of sklearn to do so. It selects the features based on the importance of their weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: FDA15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-064759cd16ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mItem_Outlet_Sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/from_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \"Since 'prefit=True', call transform directly\")\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: FDA15"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "feature = SelectFromModel(model)\n",
    "Fit = feature.fit_transform(df, train.Item_Outlet_Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Backward Feature Elimination\n",
    "\n",
    "Follow the below steps to understand and use the ‘Backward Feature Elimination’ technique:\n",
    "\n",
    "We first take all the n variables present in our dataset and train the model using them We then calculate the performance of the model\n",
    "\n",
    "Now, we compute the performance of the model after eliminating each variable (n times), i.e., we drop one variable every time and train the model on the remaining n-1 variables\n",
    "\n",
    "We identify the variable whose removal has produced the smallest (or no) change in the performance of the model, and then drop that variable Repeat this process until no variable can be dropped\n",
    "\n",
    "### This method can be used when building Linear Regression or Logistic Regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  recursive feature elimination (RFE) \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import datasets\n",
    "lreg = LinearRegression()\n",
    "rfe = RFE(lreg, 10)\n",
    "rfe = rfe.fit_transform(df, train.Item_Outlet_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
      "0         9.30         0.016047  249.8092                       1999   \n",
      "1         5.92         0.019278   48.2692                       2009   \n",
      "2        17.50         0.016760  141.6180                       1999   \n",
      "3        19.20         0.000000  182.0950                       1998   \n",
      "4         8.93         0.000000   53.8614                       1987   \n",
      "\n",
      "   Item_Outlet_Sales  Item_Identifier_DRA12  Item_Identifier_DRA24  \\\n",
      "0          3735.1380                      0                      0   \n",
      "1           443.4228                      0                      0   \n",
      "2          2097.2700                      0                      0   \n",
      "3           732.3800                      0                      0   \n",
      "4           994.7052                      0                      0   \n",
      "\n",
      "   Item_Identifier_DRA59  Item_Identifier_DRB01  Item_Identifier_DRB13  \\\n",
      "0                      0                      0                      0   \n",
      "1                      0                      0                      0   \n",
      "2                      0                      0                      0   \n",
      "3                      0                      0                      0   \n",
      "4                      0                      0                      0   \n",
      "\n",
      "               ...                Outlet_Size_High  Outlet_Size_Medium  \\\n",
      "0              ...                               0                   1   \n",
      "1              ...                               0                   1   \n",
      "2              ...                               0                   1   \n",
      "3              ...                               0                   0   \n",
      "4              ...                               1                   0   \n",
      "\n",
      "   Outlet_Size_Small  Outlet_Location_Type_Tier 1  \\\n",
      "0                  0                            1   \n",
      "1                  0                            0   \n",
      "2                  0                            1   \n",
      "3                  0                            0   \n",
      "4                  0                            0   \n",
      "\n",
      "   Outlet_Location_Type_Tier 2  Outlet_Location_Type_Tier 3  \\\n",
      "0                            0                            0   \n",
      "1                            0                            1   \n",
      "2                            0                            0   \n",
      "3                            0                            1   \n",
      "4                            0                            1   \n",
      "\n",
      "   Outlet_Type_Grocery Store  Outlet_Type_Supermarket Type1  \\\n",
      "0                          0                              1   \n",
      "1                          0                              0   \n",
      "2                          0                              1   \n",
      "3                          1                              0   \n",
      "4                          0                              1   \n",
      "\n",
      "   Outlet_Type_Supermarket Type2  Outlet_Type_Supermarket Type3  \n",
      "0                              0                              0  \n",
      "1                              1                              0  \n",
      "2                              0                              0  \n",
      "3                              0                              0  \n",
      "4                              0                              0  \n",
      "\n",
      "[5 rows x 1605 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-de12b8f61046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nFEATUERS SELECTED\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/rfe.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/rfe.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# self.scores_ will not be calculated when calling _fit through fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lei.ai/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# read the data\n",
    "train = pd.read_csv('train_kOBLwZA.csv')\n",
    "train=pd.get_dummies(train)\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "\n",
    "# seperate the target and independent variable\n",
    "X = train.drop(columns = ['Item_Outlet_Sales'],axis=1)\n",
    "Y = train['Item_Outlet_Sales']\n",
    "\n",
    "\n",
    "# create the object of the model\n",
    "lreg = LinearRegression()\n",
    "\n",
    "\n",
    "# specify the number of  features to select \n",
    "rfe = RFE(lreg, 10)\n",
    "\n",
    "# fit the model\n",
    "rfe = rfe.fit(X, Y)\n",
    "\n",
    "print('\\n\\nFEATUERS SELECTED\\n\\n')\n",
    "print(rfe.support_)\n",
    "\n",
    "print('\\n\\nRANKING OF FEATURES\\n\\n')\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Forward Feature Selection\n",
    "This is the opposite process of the Backward Feature Elimination we saw above. Instead of eliminating features, we try to find the best features which improve the performance of the model. This technique works as follows:\n",
    "\n",
    "We start with a single feature. Essentially, we train the model n number of times using each feature separately\n",
    "\n",
    "The variable giving the best performance is selected as the starting variable\n",
    "\n",
    "Then we repeat this process and add one variable at a time. The variable that produces the highest increase in performance is retained\n",
    "\n",
    "We repeat this process until no significant improvement is seen in the model’s performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "ffs = f_regression(df,train.Item_Outlet_Sales )\n",
    "\n",
    "variable = [ ]\n",
    "for i in range(0,len(df.columns)-1):\n",
    "    if ffs[0][i] >=10:\n",
    "       variable.append(df.columns[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the top most variables based on the forward feature selection algorithm.\n",
    "\n",
    "### NOTE : Both Backward Feature Elimination and Forward Feature Selection are time consuming and computationally expensive.They are practically only used on datasets that have a small number of input variables.\n",
    "\n",
    "The techniques we have seen so far are generally used when we do not have a very large number of variables in our dataset. These are more or less feature selection techniques. In the upcoming sections, we will be working with the Fashion MNIST dataset, which consists of images belonging to different types of apparel, e.g. T-shirt, trousers, bag, etc. The dataset can be downloaded from the “IDENTIFY THE APPAREL” practice problem.\n",
    "\n",
    "The dataset has a total of 70,000 images, out of which 60,000 are in the training set and the remaining 10,000 are test images. For the scope of this article, we will be working only on the training images. The train file is in a zip format. Once you extract the zip file, you will get a .csv file and a train folder which includes these 60,000 images. The corresponding label of each image can be found in the ‘train.csv’ file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Factor Analysis\n",
    "Suppose we have two variables: Income and Education. These variables will potentially have a high correlation as people with a higher education level tend to have significantly higher income, and vice versa.\n",
    "\n",
    "In the Factor Analysis technique, variables are grouped by their correlations, i.e., all variables in a particular group will have a high correlation among themselves, but a low correlation with variables of other group(s). Here, each group is known as a factor. These factors are small in number as compared to the original dimensions of the data. However, these factors are difficult to observe.\n",
    "\n",
    "Let’s first read in all the images contained in the train folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "images = [cv2.imread(file) for file in glob('train/*.png')]\n",
    "\n",
    "images = np.array(images)\n",
    "images.shape\n",
    "\n",
    "image = []\n",
    "for i in range(0,60000):\n",
    "    img = images[i].flatten()\n",
    "    image.append(img)\n",
    "image = np.array(image)\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")     # Give the complete path of your train.csv file\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(image.shape[1]) ]\n",
    "df = pd.DataFrame(image,columns=feat_cols)\n",
    "df['label'] = train['label']\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "FA = FactorAnalysis(n_components = 3).fit_transform(df[feat_cols].values)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Factor Analysis Components')\n",
    "plt.scatter(FA[:,0], FA[:,1])\n",
    "plt.scatter(FA[:,1], FA[:,2])\n",
    "plt.scatter(FA[:,2],FA[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
